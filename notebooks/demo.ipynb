{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d22ab8-e1cd-476a-8906-517f8a56b747",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21648986-1e02-4621-8576-4dbe28a78f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import datetime as dt\n",
    "from arcticdb import Arctic, LibraryOptions, QueryBuilder, LazyDataFrame, OutputFormat\n",
    "from arcticdb.version_store.library import Library\n",
    "from arcticdb.version_store.processing import ExpressionNode\n",
    "from arcticdb_ext.version_store import OperationType\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ab646-4b1f-4e47-b304-e6c65bd8282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(table):\n",
    "    print(pl.from_arrow(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df025d-00d8-4437-b532-f20922036cdd",
   "metadata": {},
   "source": [
    "## ArcticDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ca4ae-094b-4c8c-a3b5-ba8a0ccb8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uri = \"lmdb://tmp/polars_integration\"\n",
    "test_lib_name = \"polars\"\n",
    "test_symbol = \"pls\"\n",
    "ac = Arctic(test_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf2a89-2216-40c0-b812-899b7394f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.delete_library(test_lib_name)\n",
    "lib = ac.create_library(test_lib_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af004e7e-1c77-4da0-b272-f51a3d2e39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": np.arange(10, dtype=np.int64), \"col2\": np.arange(10, 20, dtype=np.float64)})\n",
    "lib.write(test_symbol, df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d2121-cd84-40cc-adb7-8b4c900239ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_frame = lib.read(test_symbol, output_format=OutputFormat.PYARROW, lazy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4072340-16b8-4307-9a98-848b34ff8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_table(lazy_frame.collect().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec27ba-f69c-4b0b-937f-e3036e4acf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = QueryBuilder()\n",
    "q = q[(q[\"col1\"] > 2) & (q[\"col2\"] < 18)]\n",
    "lazy_frame2 = lib.read(test_symbol, query_builder = q, output_format=OutputFormat.PYARROW, lazy = True)\n",
    "print_table(lazy_frame2.collect().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a003d7-f7e4-44b2-a813-bd5f39562e2b",
   "metadata": {},
   "source": [
    "## Polars expression AST parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28845c4-f126-4d01-a9ad-3f0b870224be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "from typing import Any, Optional\n",
    "\n",
    "\n",
    "class PolarsToArcticDBTranslator:\n",
    "    \"\"\"\n",
    "    Translates Polars expressions to ArcticDB QueryBuilder operations.\n",
    "    \n",
    "    Usage:\n",
    "        translator = PolarsToArcticDBTranslator()\n",
    "        qb = translator.translate(polars_expr, query_builder)\n",
    "    \"\"\"\n",
    "\n",
    "    def translate(self, polars_expr: str, query_builder: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Translate a Polars expression string to ArcticDB QueryBuilder operations.\n",
    "        \n",
    "        Args:\n",
    "            polars_expr: String representation of Polars expression\n",
    "            query_builder: ArcticDB QueryBuilder instance\n",
    "            \n",
    "        Returns:\n",
    "            Modified QueryBuilder instance\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean the expression - remove surrounding brackets if present\n",
    "        expr = polars_expr.strip()\n",
    "        if expr.startswith('[') and expr.endswith(']'):\n",
    "            expr = expr[1:-1].strip()\n",
    "\n",
    "        expr = self._replace_square_brackets(expr)\n",
    "        \n",
    "        # Preprocess to handle Polars-specific notation like [dyn int: 2]\n",
    "        expr = self._preprocess_expression(expr)\n",
    "\n",
    "         # Parse the expression\n",
    "        try:\n",
    "            tree = ast.parse(expr, mode='eval')\n",
    "            expr_node = self._process_node(tree.body)\n",
    "        except SyntaxError as e:\n",
    "            raise ValueError(f\"Invalid Polars expression: {polars_expr}\") from e\n",
    "        \n",
    "        return query_builder[expr_node]\n",
    "        \n",
    "    def _replace_square_brackets(self, text: str) -> str:\n",
    "        while True:\n",
    "            close = text.rfind('])')\n",
    "            if close == -1:\n",
    "                break\n",
    "            open_ = text.rfind('([', 0, close)\n",
    "            if open_ == -1:\n",
    "                break\n",
    "            # Replace the matched ([...]) with (...)\n",
    "            text = text[:open_] + '(' + text[open_ + 2:close] + ')' + text[close + 2:]\n",
    "        return text\n",
    "    \n",
    "    def _preprocess_expression(self, expr: str) -> str:\n",
    "        \"\"\"\n",
    "        Preprocess Polars expression to handle special notation.\n",
    "        \n",
    "        Converts patterns like [dyn int: 2] to just the value (2).\n",
    "        \"\"\"\n",
    "        # Pattern to match [dyn type: value] or [lit type: value]\n",
    "        pattern = r'[\\[\\(](dyn|lit)\\s+\\w+:\\s*([^\\]\\)]+)[\\]\\)]'\n",
    "        \n",
    "        def replace_dynamic(match):\n",
    "            return match.group(2).strip()\n",
    "        \n",
    "        return re.sub(pattern, replace_dynamic, expr)\n",
    "\n",
    "    def _process_node(self, node: ast.AST) -> Any:\n",
    "        \"\"\"Process an AST node and apply corresponding ArcticDB operation.\"\"\"\n",
    "\n",
    "        node_type = type(node)\n",
    "        match node_type:\n",
    "            case ast.Call:\n",
    "                return self._process_call(node)\n",
    "            case ast.Attribute:\n",
    "                return self._process_attribute(node)\n",
    "            case ast.Name:\n",
    "                return node.id\n",
    "            case ast.Constant:\n",
    "                return node.value\n",
    "            case ast.Compare:\n",
    "                return self._process_compare(node)\n",
    "            case ast.BinOp:\n",
    "                return self._process_binop(node)\n",
    "            case ast.UnaryOp:\n",
    "                return self._process_unaryop(node)\n",
    "            #case ast.List:\n",
    "            #    return [self._process_node(elt) for elt in node.elts]\n",
    "            #case ast.Tuple:\n",
    "            #    return tuple(self._process_node(elt) for elt in node.elts)\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Node type {node_type.__name__} not supported\")\n",
    "\n",
    "    def _process_call(self, node: ast.Call) -> Any:\n",
    "        \"\"\"Process function calls (e.g., pl.col(), methods).\"\"\"\n",
    "\n",
    "        func_type = type(node.func)\n",
    "        match func_type:\n",
    "            case ast.Attribute:\n",
    "                # TODO: rework this\n",
    "                # Method call like pl.col('x').sum()\n",
    "                #obj = self._process_node(node.func.value)\n",
    "                #method = node.func.attr\n",
    "                #args = [self._process_node(arg) for arg in node.args]\n",
    "                #kwargs = {kw.arg: self._process_node(kw.value) for kw in node.keywords}\n",
    "                \n",
    "                #return self._apply_method(obj, method, args, kwargs)\n",
    "                raise NotImplementedError(f\"Node.func type ast.Attribute not supported\")\n",
    "            \n",
    "            case ast.Name:\n",
    "                # Function call like col('x')\n",
    "                func_name = node.func.id\n",
    "                args = [self._process_node(arg) for arg in node.args]\n",
    "                \n",
    "                if func_name == 'col':\n",
    "                    return ExpressionNode.column_ref(args[0]) if args else None\n",
    "            case _:\n",
    "                return None\n",
    "\n",
    "    def _process_attribute(self, node: ast.Attribute) -> Any:\n",
    "        \"\"\"Process attribute access like pl.col or obj.attr.\"\"\"\n",
    "        #TODO rework this\n",
    "        obj = self._process_node(node.value)\n",
    "        attr = node.attr\n",
    "\n",
    "        # Handle pl.col pattern\n",
    "        #if obj == 'pl' and attr == 'col':\n",
    "        #    return 'col'\n",
    "        \n",
    "        #return f\"{obj}.{attr}\"\n",
    "        raise NotImplementedError(f\"{obj}.{attr}: Node type ast.Attribute not supported\")\n",
    "\n",
    "    def _process_compare(self, node: ast.Compare) -> Any:\n",
    "        \"\"\"Process comparison operations and apply filters.\"\"\"\n",
    "        \n",
    "        left = self._process_node(node.left)\n",
    "        \n",
    "        # Handle multiple comparisons\n",
    "        for op, comparator in zip(node.ops, node.comparators):\n",
    "            right = self._process_node(comparator)\n",
    "            expr_node = None\n",
    "            op_type = type(op)\n",
    "\n",
    "            match op_type:\n",
    "                case ast.Eq:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.EQ, right)\n",
    "                case ast.NotEq:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.NE, right)\n",
    "                case ast.Lt:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.LT, right)\n",
    "                case ast.LtE:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.LE, right)\n",
    "                case ast.Gt:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.GT, right)\n",
    "                case ast.GtE:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.GE, right)\n",
    "                case ast.In:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.ISIN, right)\n",
    "                case ast.NotIn:\n",
    "                    expr_node = ExpressionNode.compose(left, OperationType.ISNOTIN, right)\n",
    "                case _:\n",
    "                    raise NotImplementedError(f\"Operator {op_type} not supported\")\n",
    "            left = expr_node\n",
    "        \n",
    "        return expr_node\n",
    "\n",
    "    def _process_binop(self, node: ast.BinOp) -> Any:\n",
    "        \"\"\"Process binary operations.\"\"\"\n",
    "        \n",
    "        left = self._process_node(node.left)\n",
    "        \n",
    "        right = self._process_node(node.right)\n",
    "        op_type = type(node.op)\n",
    "\n",
    "        match op_type:\n",
    "            case ast.Add:\n",
    "                return ExpressionNode.compose(left, OperationType.ADD, right)\n",
    "            case ast.Sub:\n",
    "                return ExpressionNode.compose(left, OperationType.SUB, right)\n",
    "            case ast.Mult:\n",
    "                return ExpressionNode.compose(left, OperationType.MUL, right)\n",
    "            case ast.Div:\n",
    "                return ExpressionNode.compose(left, OperationType.DIV, right)\n",
    "            # TODO: operator & and | can be used for boolean operations between\n",
    "            # filters, or bitwise operations between integers values. The current\n",
    "            # implementation supports boolean operations only (which should be\n",
    "            # the most common case)\n",
    "            case ast.BitOr:\n",
    "                return ExpressionNode.compose(left, OperationType.OR, right)\n",
    "            case ast.BitAnd:\n",
    "                return ExpressionNode.compose(left, OperationType.AND, right)\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Operator {op_type} not supported\")\n",
    "    \n",
    "    def _process_unaryop(self, node: ast.UnaryOp) -> Any:\n",
    "        \"\"\"Process unary operations.\"\"\"\n",
    "        \n",
    "        operand = self._process_node(node.operand)\n",
    "        op_type = type(node.op)\n",
    "\n",
    "        match op_type:\n",
    "            case ast.Invert:\n",
    "                return ExpressionNode.compose(operand, OperationType.NOT, None)\n",
    "            case ast.USub:\n",
    "                return ExpressionNode.compose(operand, OperationType.NEG, None)\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Operator {op_type} not supported\")\n",
    "            \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea771eba-d179-4e5a-8304-a91e429c355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = PolarsToArcticDBTranslator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a498e7d-d46d-4742-abf9-8c41b07de685",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QueryBuilder()\n",
    "qb = translator.translate(str(pl.col(\"col1\") > 2), qb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869ed81-f0c1-4cc8-898a-1c9a24eaf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_frame2 = lib.read(test_symbol, query_builder = qb, output_format=OutputFormat.PYARROW, lazy = True)\n",
    "print_table(lazy_frame2.collect().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10029a-bda5-46e6-b577-65d660a5fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QueryBuilder()\n",
    "qb = translator.translate(str((pl.col(\"col1\") > 2) & (pl.col(\"col2\") < 18)), qb)\n",
    "\n",
    "qe = QueryBuilder()\n",
    "qe = qe[(qe[\"col1\"] > 2) & (qe[\"col2\"] < 18)]\n",
    "qb == qe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddac44-bb3e-473d-9829-3fde0985ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QueryBuilder()\n",
    "qb = translator.translate(str(pl.col(\"col2\") + pl.col(\"col2\") + pl.col(\"col2\")), qb)\n",
    "\n",
    "qe = QueryBuilder()\n",
    "qe = qe[qe[\"col2\"] + qe[\"col2\"] + qe[\"col2\"]]\n",
    "qb == qe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129466ff-9c4d-4153-aee4-55c15a7a7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_expr = pl.col(\"weight\") / (pl.col(\"height\") ** 2)\n",
    "qb = QueryBuilder()\n",
    "qb = translator.translate(str(bmi_expr), qb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49809451-2556-47b5-8950-b88ecb30ef1e",
   "metadata": {},
   "source": [
    "## Polars Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce536b-6643-432e-badc-49e49da0bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_schema(\n",
    "    lib: Library,\n",
    "    symbol: str,\n",
    "    as_of: int | str | dt.datetime | None = None\n",
    ") -> pl.Schema:\n",
    "    arrow_df = lib.read(symbol, as_of=as_of, output_format=OutputFormat.PYARROW, row_range=((0,1))).data\n",
    "    return pl.Schema(arrow_df.schema) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff39bc-12fa-4c94-9fdd-719b2be3219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_arcticdb(\n",
    "    uri: str,\n",
    "    lib_name: str,\n",
    "    symbol: str,\n",
    "    as_of: int | str | dt.datetime | None = None\n",
    ") -> pl.LazyFrame:\n",
    "\n",
    "    ac = Arctic(uri)\n",
    "    lib = ac.get_library(lib_name)\n",
    "\n",
    "    schema = parse_schema(lib, symbol, as_of)\n",
    "\n",
    "    def source_generator(\n",
    "        with_columns: list[str] | None,\n",
    "        predicate: pl.Expr | None,\n",
    "        n_rows: int | None,\n",
    "        batch_size: int | None\n",
    "    ) -> Iterator[pl.DataFrame]:\n",
    "        if predicate is not None:\n",
    "            print(str(predicate))\n",
    "        else:\n",
    "            print(\"No Predicate\")\n",
    "\n",
    "        if with_columns:\n",
    "            print(with_columns)\n",
    "        else:\n",
    "            print(\"No column\")\n",
    "\n",
    "        qb = None\n",
    "        if predicate is not None:\n",
    "            tl = PolarsToArcticDBTranslator()\n",
    "            qb = QueryBuilder()\n",
    "            qb = tl.translate(str(predicate), qb)\n",
    "            \n",
    "        # TODO: convert predicate to QueryBuilder and pass it to read\n",
    "        lazy_df = lib.read(symbol, as_of = as_of, columns = with_columns, query_builder = qb, lazy = True, output_format=OutputFormat.PYARROW)\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = 1000\n",
    "\n",
    "        if n_rows is not None:\n",
    "            batch_size = min(batch_size, n_rows)\n",
    "        \n",
    "        read_idx = 0\n",
    "        while n_rows is None or n_rows > 0:\n",
    "            lazy_df_slice = lazy_df.row_range((read_idx, read_idx + batch_size))\n",
    "            read_idx += batch_size\n",
    "            arrow_df = lazy_df_slice.collect().data\n",
    "            if n_rows is not None:\n",
    "                n_rows -= arrow_df.num_rows\n",
    "            elif arrow_df.num_rows < batch_size:\n",
    "                n_rows = 0\n",
    "\n",
    "            yield pl.from_arrow(arrow_df)\n",
    "\n",
    "    return pl.io.plugins.register_io_source(io_source=source_generator, schema = schema)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079c4d7-fe11-4f27-b615-380c7e29a128",
   "metadata": {},
   "source": [
    "## Plugin tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65870e4c-58a8-4482-8f76-489f14935a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_frame = scan_arcticdb(test_uri, test_lib_name, test_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb004f60-21b1-4be8-9c09-1a6bf96f06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_frame.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6c141-f406-4439-b07b-e2b112fe84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_frame.select(pl.col(\"col1\"))\n",
    "pl_frame.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01886b1-cd91-4c78-8654-7bcac665ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_frame.select(pl.col(\"col1\") / pl.col(\"col2\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03241e8f-a5be-4f50-8448-ba5a248da62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl_frame.filter(pl.col(\"col1\") > 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58b071-cdac-4123-a6f9-8f93b108b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_frame.filter((pl.col(\"col1\") > 2) & (pl.col(\"col2\") < 18)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e077e-ca09-4544-9dac-39d449ce656f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
